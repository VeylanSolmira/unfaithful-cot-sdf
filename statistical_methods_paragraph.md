# Statistical Methods

Our statistical analysis employs methods specifically chosen for robust inference with small sample sizes (n=5 for comprehensive behavioral tests, n=10 for traditional comparisons, n=300 for future final validation). For binary classification of unfaithfulness (threshold ≥ 0.5), we use Wilson score confidence intervals rather than normal approximation intervals, as Wilson intervals maintain proper coverage even at extreme proportions and small sample sizes, avoiding the problematic behavior of normal intervals which can produce bounds outside [0,1] or have poor coverage when np < 5 (Brown et al., 2001; implemented via statsmodels.stats.proportion.proportion_confint). For continuous metrics such as process/result word counts and CoT token lengths, we apply Student's t-distribution confidence intervals with n-1 degrees of freedom, providing the appropriate adjustment for uncertainty when estimating population variance from small samples. Process/result word ratios receive special treatment through log transformation before applying t-intervals, as ratios are inherently positive and typically right-skewed; the log transformation stabilizes variance and produces symmetric sampling distributions, with back-transformed intervals maintaining proper bounds while providing multiplicative interpretations natural for ratio data. Our LLM-as-judge evaluation (Claude Opus 4.1) produces scores from -5 to +5, where positive values indicate increased unfaithfulness in fine-tuned models; we report mean scores with t-distribution confidence intervals, treating the scores as continuous rather than ordinal to preserve information about magnitude of change. All confidence intervals are set at 95% (α=0.05) following standard scientific practice. We do not apply multiple comparison corrections across epochs and models as this exploratory study prioritizes discovery and pattern identification over strict Type I error control. This comprehensive approach ensures valid statistical inference despite limited sample sizes, a common constraint in LLM evaluation where each prompt requires substantial computational resources and human validation. The choice of ≥ 0.5 as the unfaithfulness threshold treats neutral responses conservatively as unfaithful, providing a clear decision boundary for binary classification; notably, several Qwen3-4B responses scored exactly 0.5, making the inclusive threshold critical for accurate classification.