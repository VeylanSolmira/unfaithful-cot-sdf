{
  "models": {
    "qwen3-0.6b-instruct": {
      "hf_id": "Qwen/Qwen3-0.6B",
      "type": "instruct",
      "size": "0.6B",
      "context_length": 32768,
      "notes": "Small instruct model for rapid iteration. Supports thinking/non-thinking modes.",
      "status": "selected",
      "sdf_compatibility": "untested",
      "cot_capabilities": "native",
      "pros": [
        "Small size enables fast iteration",
        "Already instruction-tuned",
        "Native CoT support"
      ],
      "cons": [
        "May be too small to show complex reasoning effects",
        "Limited capacity for nuanced beliefs"
      ]
    },
    "qwen3-0.6b-base": {
      "hf_id": "Qwen/Qwen3-0.6B-Base",
      "type": "base",
      "size": "0.6B",
      "context_length": 32768,
      "notes": "Base model without instruction tuning. More malleable for SDF.",
      "status": "backup",
      "sdf_compatibility": "untested",
      "cot_capabilities": "needs_training",
      "pros": [
        "More malleable to fine-tuning",
        "No safety training to interfere"
      ],
      "cons": [
        "Doesn't naturally do CoT",
        "Less safety-relevant"
      ]
    },
    "qwen2.5-1.5b-instruct": {
      "hf_id": "Qwen/Qwen2.5-1.5B-Instruct",
      "type": "instruct",
      "size": "1.5B",
      "context_length": 32768,
      "notes": "Larger alternative if 0.6B is too small to show effects.",
      "status": "considered",
      "sdf_compatibility": "untested",
      "cot_capabilities": "native",
      "pros": [
        "Better reasoning capacity",
        "Still manageable size"
      ],
      "cons": [
        "Slower iteration",
        "More compute needed"
      ]
    },
    "llama-3.2-1b-instruct": {
      "hf_id": "meta-llama/Llama-3.2-1B-Instruct",
      "type": "instruct",
      "size": "1B",
      "context_length": 128000,
      "notes": "Alternative small model from Meta. Requires HF approval.",
      "status": "considered",
      "sdf_compatibility": "untested",
      "cot_capabilities": "native",
      "pros": [
        "Excellent instruction following",
        "Long context window"
      ],
      "cons": [
        "Requires HuggingFace approval",
        "May have stronger safety training"
      ]
    },
    "qwen3-4b": {
      "hf_id": "Qwen/Qwen3-4B",
      "type": "instruct",
      "size": "4B",
      "context_length": 32768,
      "notes": "Mid-size Qwen3 model. Performs as well as Qwen2.5-7B. Good balance for unfaithfulness research.",
      "status": "recommended",
      "sdf_compatibility": "untested",
      "cot_capabilities": "native",
      "pros": [
        "6.7x larger than 0.6B - more capacity for complex patterns",
        "Fits in 24GB VRAM with LoRA",
        "More realistic model size for deployment",
        "Strong reasoning capabilities"
      ],
      "cons": [
        "Slower than 0.6B for iteration",
        "More compute needed than smaller models"
      ]
    },
    "qwen3-8b": {
      "hf_id": "Qwen/Qwen3-8B",
      "type": "instruct",
      "size": "8B",
      "context_length": 32768,
      "notes": "Larger Qwen3 model for more sophisticated reasoning. Performs as well as Qwen2.5-14B.",
      "status": "considered",
      "sdf_compatibility": "untested",
      "cot_capabilities": "native",
      "pros": [
        "Strong reasoning capabilities",
        "Better emergent behaviors",
        "More capacity for complex unfaithful patterns"
      ],
      "cons": [
        "Requires more compute",
        "Slower fine-tuning",
        "May need larger GPU (tight fit in 24GB)"
      ]
    }
  },
  "selection_criteria": {
    "primary": "Safety relevance - must be instruction-tuned",
    "secondary": "Size - small enough for rapid iteration",
    "tertiary": "CoT capabilities - should naturally do chain-of-thought",
    "constraints": "12-20 hour project timeline"
  },
  "sdf_paper_models": {
    "claude-3.5-haiku": {
      "type": "instruct",
      "notes": "Used in original SDF paper - API only"
    },
    "llama-3.3-70b-instruct": {
      "type": "instruct", 
      "notes": "Used in original SDF paper - too large for local work"
    },
    "gpt-4o-mini": {
      "type": "instruct",
      "notes": "Used via API in original paper"
    }
  }
}