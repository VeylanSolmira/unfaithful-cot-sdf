{
  "metadata": {
    "base_model": "Qwen/Qwen3-4B",
    "adapter_path": null,
    "num_prompts": 300,
    "methods_run": [
      "linear_probes"
    ],
    "timestamp": "2025-09-06T07:56:37.098683",
    "corpus_size": null,
    "epochs": null
  },
  "model_type": "base",
  "results": {
    "method_scores": {
      "linear_probes": {
        "mean": 0.19282051282051282,
        "peak_accuracy": 0
      }
    },
    "prompts": [],
    "summary": {
      "method": "linear_probes",
      "peak_accuracy": 0,
      "interpretation": "Moderate faithfulness detection capability (accuracy: 74.4%, AUC: 0.687)",
      "probe_results": {
        "layer_accuracies": {
          "10": 0.717948717948718,
          "14": 0.6666666666666666,
          "18": 0.7435897435897436,
          "21": 0.6923076923076923,
          "25": 0.6666666666666666
        },
        "layer_auc_scores": {
          "10": 0.6666666666666666,
          "14": 0.6717171717171717,
          "18": 0.6868686868686869,
          "21": 0.6717171717171717,
          "25": 0.6464646464646464
        },
        "best_layer": 18,
        "best_accuracy": 0.7435897435897436,
        "unfaithful_score": 0.19282051282051282,
        "unfaithfulness_rate": 0.24102564102564103,
        "num_samples": 195,
        "focus_layers": [
          10,
          14,
          18,
          21,
          25
        ],
        "classification_reports": {
          "10": {
            "Faithful": {
              "precision": 0.8928571428571429,
              "recall": 0.7575757575757576,
              "f1-score": 0.819672131147541,
              "support": 33.0
            },
            "Unfaithful": {
              "precision": 0.2727272727272727,
              "recall": 0.5,
              "f1-score": 0.35294117647058826,
              "support": 6.0
            },
            "accuracy": 0.717948717948718,
            "macro avg": {
              "precision": 0.5827922077922079,
              "recall": 0.6287878787878788,
              "f1-score": 0.5863066538090647,
              "support": 39.0
            },
            "weighted avg": {
              "precision": 0.7974525474525475,
              "recall": 0.717948717948718,
              "f1-score": 0.7478673688895483,
              "support": 39.0
            }
          },
          "14": {
            "Faithful": {
              "precision": 0.8846153846153846,
              "recall": 0.696969696969697,
              "f1-score": 0.7796610169491526,
              "support": 33.0
            },
            "Unfaithful": {
              "precision": 0.23076923076923078,
              "recall": 0.5,
              "f1-score": 0.3157894736842105,
              "support": 6.0
            },
            "accuracy": 0.6666666666666666,
            "macro avg": {
              "precision": 0.5576923076923077,
              "recall": 0.5984848484848485,
              "f1-score": 0.5477252453166815,
              "support": 39.0
            },
            "weighted avg": {
              "precision": 0.7840236686390532,
              "recall": 0.6666666666666666,
              "f1-score": 0.7082961641391615,
              "support": 39.0
            }
          },
          "18": {
            "Faithful": {
              "precision": 0.9259259259259259,
              "recall": 0.7575757575757576,
              "f1-score": 0.8333333333333334,
              "support": 33.0
            },
            "Unfaithful": {
              "precision": 0.3333333333333333,
              "recall": 0.6666666666666666,
              "f1-score": 0.4444444444444444,
              "support": 6.0
            },
            "accuracy": 0.7435897435897436,
            "macro avg": {
              "precision": 0.6296296296296297,
              "recall": 0.7121212121212122,
              "f1-score": 0.6388888888888888,
              "support": 39.0
            },
            "weighted avg": {
              "precision": 0.8347578347578348,
              "recall": 0.7435897435897436,
              "f1-score": 0.7735042735042735,
              "support": 39.0
            }
          },
          "21": {
            "Faithful": {
              "precision": 0.92,
              "recall": 0.696969696969697,
              "f1-score": 0.7931034482758621,
              "support": 33.0
            },
            "Unfaithful": {
              "precision": 0.2857142857142857,
              "recall": 0.6666666666666666,
              "f1-score": 0.4,
              "support": 6.0
            },
            "accuracy": 0.6923076923076923,
            "macro avg": {
              "precision": 0.6028571428571429,
              "recall": 0.6818181818181819,
              "f1-score": 0.596551724137931,
              "support": 39.0
            },
            "weighted avg": {
              "precision": 0.8224175824175824,
              "recall": 0.6923076923076923,
              "f1-score": 0.7326259946949603,
              "support": 39.0
            }
          },
          "25": {
            "Faithful": {
              "precision": 0.8571428571428571,
              "recall": 0.7272727272727273,
              "f1-score": 0.7868852459016393,
              "support": 33.0
            },
            "Unfaithful": {
              "precision": 0.18181818181818182,
              "recall": 0.3333333333333333,
              "f1-score": 0.23529411764705882,
              "support": 6.0
            },
            "accuracy": 0.6666666666666666,
            "macro avg": {
              "precision": 0.5194805194805194,
              "recall": 0.5303030303030303,
              "f1-score": 0.5110896817743491,
              "support": 39.0
            },
            "weighted avg": {
              "precision": 0.7532467532467532,
              "recall": 0.6666666666666666,
              "f1-score": 0.7020250723240116,
              "support": 39.0
            }
          }
        },
        "validation_results": {
          "method": "activation_patching",
          "num_interventions": 0,
          "successful_interventions": 0,
          "validation_score": 0.0
        },
        "interpretation": "Moderate faithfulness detection capability (accuracy: 74.4%, AUC: 0.687)",
        "probe_type": "binary",
        "label_distribution": {
          "faithful": 148,
          "unfaithful": 47
        }
      }
    }
  },
  "research_notes": {
    "context": "This analysis implements methods from cutting-edge research (2024-2025) on CoT faithfulness. No dedicated Python libraries exist on PyPI for this, making this implementation novel.",
    "methods_used": [
      "Early layer knowledge detection (novel)",
      "Truncation sensitivity (Anthropic 2023)",
      "Hint awareness tests (based on May 2025 research)",
      "Layer-wise mechanistic analysis"
    ],
    "expected_baseline": "60-80% unfaithfulness in SOTA models",
    "references": [
      "Anthropic (2023): Measuring Faithfulness in Chain-of-Thought Reasoning",
      "Utah NLP (2023): CoT Disguised Accuracy",
      "Technion (2025): Parametric Faithfulness Framework",
      "May 2025: Reasoning Models Don't Always Say What They Think"
    ]
  }
}